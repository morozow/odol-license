# Open Data Ownership License (ODOL) 18.0

### 1. Definitions

- **AI System:** Any software, platform, or application utilizing machine learning, inference models, or natural
  language processing models to generate content based on user input.
- **Input Data:** Information, including text, images, audio, or other media, submitted by the user into an AI system.
- **Output Data:** Content generated by an AI system in response to user-provided Input Data. Output Data includes
  creative content but excludes factual information commonly known or derived from training data.
- **Unique Expression:** Generated content is owned by the user if it presents original semantic meaning with a cosine
  similarity score ≤0.7 relative to known datasets, measured using industry-standard models such as Sentence-BERT,
  evaluated via open-source reproducible benchmarks.
- **Factual Information:** Universally accepted facts available in the public domain, without creative transformation.
- **Metadata:** Interaction-related data such as timestamps, IP addresses, devices used, device identifiers, user
  agents, behavioral patterns, and behavioral fingerprints, excluding content itself.
- **Behavioral Fingerprints:** Patterns derived through ISO/IEC 20889-compliant processes, excluding any data enabling
  direct or indirect user identification. Regular model updates must reflect current research findings.
- **Semantic Uniqueness:** Content with cosine similarity ≤0.7 based on domain-specific datasets using context-aware
  models (e.g., Sentence-BERT with domain embeddings). Models must be reviewed annually for robustness against
  adversarial attacks, following methodologies outlined in NIST SP 800-53 or ISO/IEC 27032. Documentation of these
  reviews must be publicly accessible. **All model changes must be accompanied by calibration reports that describe
  differences and confirm continued reliability.**
- **User:** Any individual, entity, or organization providing Input Data to an AI system.
- **Provider:** The entity operating the AI system.
- **Creative Content:** Innovative, user-influenced content that does not constitute publicly known information.
- **Publicly Known Information:** Data that is verifiable, broadly available to the public, and not attributable to any
  single individual’s input.

---

### 2. Audit Procedures

2.1. **Independent Auditor Eligibility**

- Auditors must be accredited by ISO/IEC 27001-certified organizations.
- Auditors must demonstrate verifiable expertise in AI infrastructure and privacy auditing.
- Auditors must adhere to ISO/IEC 27552, TR 24028, and ISO/IEC 24029-2 standards.
- Auditors must not have provided services to the same client within the past three (3) years.
- Independent external verification of audit results is mandatory every 2 years.

2.2. **Audit Process**

- Providers must submit a full system audit report annually.
- Audits must include verification of data deletion requests, compliance with metadata restrictions, and proper user
  consent handling.
- Auditors will utilize **Machine Unlearning Techniques** verified by an external, independent research body with proven
  expertise in AI privacy to exclude requested data from training sets.
- **Machine Unlearning verification shall follow IEEE P7003 standards, including comparative performance tests on
  control datasets and validation on representative samples for large-scale models. Results must be independently
  verified using tools such as ML Privacy Meter or Veritas Unlearn.**
- **The removal process must be tested on datasets larger than 100,000 entries to ensure reliability in large language
  models.**
- **Auditors must conduct random-sample tests from sensitive data categories to ensure full compliance.**
- **If vulnerabilities are detected, Providers must implement remediation measures within 30 days and submit a follow-up
  audit report to ODRC.**
- **Failure to address identified vulnerabilities within 30 days shall result in an automatic moderate violation,
  escalating to critical after 60 days.**

2.3. **Sanctions for Repeated Violations**

- Violations are categorized as Critical, Moderate, or Minor, with corresponding measures:
    - **Critical:** Unauthorized retention or sharing of personal data involving more than 5,000 individuals.
    - **Moderate:** Errors in audit reports affecting compliance records or impacting up to 5,000 individuals.
    - **Minor:** Incorrect formatting or non-critical documentation issues.
- **Quantitative Measurement:** Violations will be assessed based on the affected data volume:
    - > 10,000 records: Critical
    - 5,000–10,000 records: Moderate
    - <5,000 records: Minor
- Three (3) violations within 24 months: mandatory unscheduled audit.
- Five (5) violations: automatic suspension of ODOL certification until compliance is restored and verified by ODRC.
- Violations count applies to all entities directly or indirectly linked to the Provider, including rebranded or
  subsidiary organizations.

2.4. **Audit Reporting**

- Audit results must be publicly available in a standardized format.
- Reports should list data processing practices without disclosing sensitive or proprietary model architecture.
- Reports must comply with ISO/IEC 27552 standards and include metrics such as:
    - Number of deletion requests received.
    - Number of deletion requests successfully completed.
    - Accuracy percentage of data removal.
- **Providers must publish calibration reports for originality detection models, detailing methodologies and datasets
  used.**

---

### 3. Legal Adaptation

3.1. **International Compliance**

- ODOL aligns with international standards including GDPR (EU), CCPA (USA), PIPL (China), LGPD (Brazil), and ISO/IEC
  27701 for jurisdictions lacking privacy regulators.
- Providers must comply with ODOL requirements unless explicitly restricted by national law.
- Providers must review and update privacy policies annually or whenever new national or international privacy laws are
  enacted.
- **Annual external legal reviews are mandatory to identify new obligations arising from local regulatory updates.**

3.2. **Conflict Resolution**

- If a national law conflicts with ODOL, the Provider must notify the user within 30 calendar days.
- Alternative safeguards must be implemented that provide equivalent privacy protection.
- Providers must provide documented legal expertise to justify alternative measures taken.
- Providers are required to obtain and present an official document from the relevant regulatory body to substantiate
  legal conflicts.
- All international conflicts must be reported to the ODRC and, if necessary, escalated to relevant regional regulators.
- Providers must suspend relevant data processing within 48 hours upon receiving a formal legal conflict notification
  from a recognized regulator.
- **Alternative safeguards must be disclosed to affected users in plain language within 30 calendar days of
  implementation.**
- **All legal conflicts must be documented with a summary of the regulatory feedback and the Provider’s adaptation
  actions, stored for a minimum of 3 years.**

3.3. **International Dispute Resolution Mechanism**

- International conflicts shall be addressed within 60 calendar days of submission.
- Independent arbitration will be conducted under UNCITRAL Arbitration Rules with a panel of three privacy law experts.
- **If no resolution is reached within 90 days, Providers may resume operations while documenting rationale for
  continuation.**

3.4. **Legal Hierarchy**

- ODOL principles apply unless contradicted by mandatory national privacy laws explicitly governing personal data
  ownership.

3.5. **Data Localization Requirements**

- Providers must ensure that all data related to residents of the European Union is processed and stored in accordance
  with **GDPR Article 46**, including documented risk assessments for cross-border transfers.

3.6. **Recognized Regulator**

- A recognized regulator is defined as a regulatory body authorized under national or international law to oversee data
  protection practices (e.g., EDPS, FTC, Cyberspace Administration of China).

---

### 4. Technical Standards

4.1. **Content Originality Verification**

- Content originality shall be assessed using context-aware models like Sentence-BERT and supplemented with structural
  pattern analysis.
- For underrepresented languages, alternative models validated by independent research institutions may be used.
- New models must undergo calibration on benchmark datasets before deployment, with published calibration results.

4.2. **Encryption Requirements**

- All stored user data and metadata must be encrypted with AES-256.
- Data in transit must be protected using TLS 1.3 or higher.
- Key rotation shall occur every 180 days with logs maintained according to ISO/IEC 27002 standards.
- Key audit processes must be independently reviewed annually.

4.3. **Anonymization Protocols**

- Metadata must undergo anonymization using ε-Differential Privacy with ε ≤ 1.0 to prevent re-identification.
- For datasets containing biometric or health-related information, ε shall not exceed 0.3.
- ε-differential privacy may range from 0.3 to 1.0 depending on data sensitivity, with justification and approval by the
  ODRC.
- **Sensitive Data Classification:**
    - **Medical Data:** ε ≤ 0.3
    - **Financial Data:** ε ≤ 0.4
    - **General Behavioral Data:** ε ≤ 0.5
- **Verification:** Anonymization effectiveness must be verified annually with reports published for public access.

4.4. **Model Change Log Requirements**

- Providers must maintain a non-public audit log of all model updates affecting data behavior.
- Logs must detail the datasets introduced, the impact on model performance, and any metadata utilized during training.
- Training datasets must include documentation of retrieval methods and sources.
- **External auditors must validate dataset sources annually, with verification methods publicly documented.**

---

### 5. ODRC Governance

5.1. **Establishment**

- The ODOL Data Rights Council (ODRC) will be established as an independent, non-profit oversight body.

5.2. **Responsibilities**

- Maintain a public registry of AI providers adopting ODOL.
- Review audit results and issue compliance certifications.
- Mediate disputes between users and providers.
- Serve as the primary intermediary in resolving international data privacy disputes.
- ODRC shall maintain communication channels with EDPB, FTC, CNIL, and other recognized regulators for international
  data compliance.

5.3. **Governance Principles**

- The council will consist of international experts in data privacy, AI development, and legal compliance.
- Council members must disclose any potential conflicts of interest before participating in case reviews.
- Council members serve for a **two-year term** with the possibility of a single reappointment.
- **Impeachment Process**: Council members may be dismissed if found guilty of bias, misconduct, or non-compliance by a
  two-thirds (2/3) majority vote.
- **Conflict Resolution:** Members must recuse themselves from cases where conflicts of interest exist.
- In the event of a tie vote, an external arbitration panel consisting of independent privacy law experts shall decide
  by majority vote.
- **Immediate Dismissal:** Members will be immediately dismissed upon verification of conflict-of-interest concealment.

5.4. **Appeal Process**

- Users and providers can submit appeals to the ODRC within 60 days of the original decision.
- Appeals must include detailed grounds and may involve independent experts.
- Appeals will be evaluated based on new evidence, procedural errors, or audit inaccuracies.
- **All appeals must be processed within 45 calendar days.**

5.5. **Standardized Audit Reporting**

- Audit reports must follow a standardized format including:
    - Total number of deletion requests.
    - Deletion success rate.
    - Detected instances of unauthorized data use.
- Reports must be published publicly every 6 months in aggregated format to prevent exposure of commercially sensitive
  information.
- The ODRC will maintain an open database of registered providers, along with their violation history and compliance
  ratings.

---

### 6. Practical Adaptations

- **Startup Compliance:** Startups with less than $3 million annual revenue may submit simplified self-assessment
  reports instead of full external audits. Upon exceeding this threshold, they must undergo a full audit within 6
  months.
- **Startup Monitoring:** Startups must undergo a full external audit after 2 years, regardless of revenue.
- **Dataset Transparency:** Providers must document retrieval methods and sources for all publicly available datasets
  used in model training.
- **Dataset Source Verification:** Independent experts must annually verify dataset legality and document collection
  methods.

### 7. Legal Notice
The Open Data Ownership License (ODOL) is licensed under the Creative Commons Attribution-NonCommercial 4.0 International License (CC BY-NC 4.0). 

Commercial usage of this document, its derivatives, or its concepts without the author’s permission is strictly prohibited.

See details in [LICENSE_LEGAL](../LICENSE_LEGAL).

---

**Final Clause:**
This license guarantees the right of individuals and organizations to own, protect, and manage their data when
interacting with AI systems. Violations are subject to penalties defined herein and enforced via arbitration or legal
action under the user’s jurisdiction.

**"Your Data. Your Decisions. Your Rights."**

